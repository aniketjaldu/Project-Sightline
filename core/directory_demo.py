#!/usr/bin/env python3
"""
Directory Structure Demonstration & Migration Tool

This script demonstrates the new organized directory structure and provides
migration tools to move from the old flat structure to the new organized one.

Author: AI Assistant
"""

import json
import shutil
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

from core.config import (
    get_workflow_directories, ensure_directories, 
    WORKFLOWS_DIR, MODELS_ACTIVE, TEMP_DIR, DATA_ROOT
)
from utils.workflow_manager import WorkflowManager
from utils.logger import setup_logger

def demonstrate_new_structure():
    """Demonstrate the new organized directory structure"""
    print("\nğŸ¯ NEW ORGANIZED DIRECTORY STRUCTURE")
    print("=" * 60)
    
    # Create base directories
    ensure_directories()
    
    # Show the organized structure
    structure = f"""
project_data/                              # Root data directory
â”œâ”€â”€ workflows/                             # Individual workflow runs
â”‚   â”œâ”€â”€ training_20250122_143022/         # Timestamped workflow
â”‚   â”‚   â”œâ”€â”€ workflow.json                 # Workflow manifest
â”‚   â”‚   â”œâ”€â”€ inputs/                       # Raw input data
â”‚   â”‚   â”‚   â”œâ”€â”€ videos/                   # Original videos
â”‚   â”‚   â”‚   â””â”€â”€ annotations/              # Original JSON annotations
â”‚   â”‚   â”œâ”€â”€ training/                     # Training-specific data
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset/                  # YOLO dataset
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ images/          # Training images
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ labels/          # Training labels
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ val/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ images/          # Validation images
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ labels/          # Validation labels
â”‚   â”‚   â”‚   â”œâ”€â”€ configs/                 # Training configs
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/             # Training checkpoints
â”‚   â”‚   â”‚   â””â”€â”€ results/                 # Training results
â”‚   â”‚   â”œâ”€â”€ temp/                        # Temporary processing files
â”‚   â”‚   â”œâ”€â”€ outputs/                     # Final outputs
â”‚   â”‚   â”‚   â”œâ”€â”€ models/                  # Trained model files
â”‚   â”‚   â”‚   â”œâ”€â”€ videos/                  # Output videos
â”‚   â”‚   â”‚   â”œâ”€â”€ annotations/             # Output annotations
â”‚   â”‚   â”‚   â””â”€â”€ reports/                 # Analysis reports
â”‚   â”‚   â””â”€â”€ logs/                        # Workflow-specific logs
â”‚   â””â”€â”€ inference_20250122_143055/       # Inference workflow
â”‚       â”œâ”€â”€ inputs/                      # Input videos
â”‚       â”œâ”€â”€ inference/                   # Inference data
â”‚       â”œâ”€â”€ tracking/                    # Tracking method outputs
â”‚       â”‚   â”œâ”€â”€ sightline/              # Sightline tracking results
â”‚       â”‚   â”œâ”€â”€ bytetrack/              # ByteTrack tracking results
â”‚       â”‚   â”œâ”€â”€ botsort/                # BoT-SORT tracking results
â”‚       â”‚   â””â”€â”€ comparisons/            # Method comparisons
â”‚       â””â”€â”€ outputs/                    # Final outputs
â”œâ”€â”€ models/                             # Permanent model storage
â”‚   â”œâ”€â”€ active/                         # Currently active models
â”‚   â”‚   â”œâ”€â”€ my_model.pt                # Active model file
â”‚   â”‚   â””â”€â”€ my_model_info.json         # Model metadata
â”‚   â”œâ”€â”€ versions/                       # Model version history
â”‚   â””â”€â”€ pretrained/                     # Downloaded pretrained models
â”œâ”€â”€ configs/                            # Configuration files
â”‚   â”œâ”€â”€ trackers/                       # Tracking configurations
â”‚   â”œâ”€â”€ datasets/                       # Dataset configurations
â”‚   â””â”€â”€ models/                         # Model configurations
â”œâ”€â”€ temp/                              # Global temporary files
â”‚   â”œâ”€â”€ downloads/                      # Raw downloads (can be deleted)
â”‚   â”œâ”€â”€ processing/                     # Processing workspace
â”‚   â””â”€â”€ inference/                      # Inference workspace
â”œâ”€â”€ logs/                              # Centralized logging
â”‚   â”œâ”€â”€ main.log                       # Main application log
â”‚   â”œâ”€â”€ data_rows.log                  # Data row actions log
â”‚   â””â”€â”€ errors.log                     # Error-specific log
â””â”€â”€ archive/                           # Completed workflows
    â””â”€â”€ training_20250120_120000/      # Archived workflow
"""
    
    print(structure)
    print("\nğŸ“‹ KEY BENEFITS:")
    print("âœ… Clear separation of concerns")
    print("âœ… Easy to find files from specific workflows") 
    print("âœ… Temporary files clearly separated from permanent")
    print("âœ… Tracking method outputs organized")
    print("âœ… Timestamped workflows for easy identification")
    print("âœ… Models properly versioned and managed")
    print("âœ… Easy cleanup of old workflows")

def demonstrate_workflow_creation():
    """Demonstrate creating a new workflow"""
    print("\nğŸ”§ WORKFLOW CREATION DEMONSTRATION")
    print("=" * 60)
    
    manager = WorkflowManager()
    
    # Create a training workflow
    print("Creating training workflow...")
    training_workflow = manager.create_workflow('training', 'demo_training')
    
    if training_workflow['success']:
        print(f"âœ… Created training workflow: {training_workflow['workflow_id']}")
        print(f"ğŸ“ Workflow directory: {training_workflow['directories']['root']}")
        
        # Show some key directories
        dirs = training_workflow['directories']
        print(f"ğŸ“ Training dataset: {dirs['training']['dataset']}")
        print(f"ğŸ Output models: {dirs['outputs']['models']}")
        print(f"ğŸ“Š Logs: {dirs['logs']['root']}")
    else:
        print(f"âŒ Failed to create training workflow: {training_workflow.get('error', 'Unknown error')}")
    
    # Create an inference workflow
    print("\nCreating inference workflow...")
    inference_workflow = manager.create_workflow('inference', 'demo_inference')
    
    if inference_workflow['success']:
        print(f"âœ… Created inference workflow: {inference_workflow['workflow_id']}")
        dirs = inference_workflow['directories']
        print(f"ğŸ¬ Input videos: {dirs['inputs']['videos']}")
        print(f"ğŸ¯ Sightline tracking: {dirs['tracking']['sightline']}")
        print(f"ğŸ¯ ByteTrack tracking: {dirs['tracking']['bytetrack']}")
        print(f"ğŸ¯ BoT-SORT tracking: {dirs['tracking']['botsort']}")

def demonstrate_file_organization():
    """Demonstrate organized file storage"""
    print("\nğŸ“ FILE ORGANIZATION DEMONSTRATION")  
    print("=" * 60)
    
    manager = WorkflowManager()
    
    # Create demo workflow
    workflow = manager.create_workflow('inference', 'file_demo')
    
    if workflow['success']:
        dirs = workflow['directories']
        
        # Simulate saving different types of files
        demo_files = {
            'input_video': ('sample_video.mp4', 'Demo video content'),
            'input_annotation': ('sample_annotations.json', {'demo': 'data'}),
            'tracking_sightline': ('video_annotations.json', {'tracking': 'sightline_data'}),
            'tracking_bytetrack': ('video_annotations.json', {'tracking': 'bytetrack_data'}),
            'output_video': ('final_video.mp4', 'Final processed video'),
            'output_annotation': ('final_annotations.json', {'final': 'results'})
        }
        
        saved_paths = {}
        for file_type, (filename, content) in demo_files.items():
            path = manager.save_workflow_file(dirs, file_type, content, filename)
            if path:
                saved_paths[file_type] = path
                print(f"âœ… Saved {file_type}: {path}")
        
        print(f"\nğŸ“‹ Summary: Saved {len(saved_paths)} files in organized structure")

def migrate_old_structure():
    """Migration tool from old flat structure to new organized structure"""
    print("\nğŸ”„ MIGRATION FROM OLD STRUCTURE")
    print("=" * 60)
    
    # Check if old structure exists
    old_workflow_data = Path("workflow_data")
    
    if not old_workflow_data.exists():
        print("â„¹ï¸ No old 'workflow_data' directory found - nothing to migrate")
        return
    
    print(f"ğŸ“ Found old structure at: {old_workflow_data}")
    
    # Ask for confirmation
    response = input("\nâš ï¸ Do you want to migrate to the new structure? (y/N): ").strip().lower()
    if response != 'y':
        print("Migration cancelled")
        return
    
    logger = setup_logger("Migration")
    manager = WorkflowManager()
    
    try:
        # Create migration workflow
        migration = manager.create_workflow('migration', 'structure_migration')
        
        if not migration['success']:
            print(f"âŒ Failed to create migration workflow: {migration.get('error')}")
            return
        
        migration_dir = migration['directories']['root']
        migrated_files = 0
        
        # Migrate downloads
        old_downloads = old_workflow_data / "downloads"
        if old_downloads.exists():
            new_downloads = TEMP_DIR / "downloads"
            print(f"ğŸ”„ Migrating downloads: {old_downloads} -> {new_downloads}")
            
            for file_path in old_downloads.iterdir():
                if file_path.is_file():
                    dest_path = new_downloads / file_path.name
                    shutil.copy2(file_path, dest_path)
                    migrated_files += 1
        
        # Migrate models to active models
        old_models = old_workflow_data / "models"
        if old_models.exists():
            print(f"ğŸ”„ Migrating models: {old_models} -> {MODELS_ACTIVE}")
            
            for file_path in old_models.rglob("*.pt"):
                if file_path.is_file():
                    # Try to determine model name from path
                    if file_path.parent.name == "weights" and file_path.name == "best.pt":
                        model_name = file_path.parent.parent.name
                    else:
                        model_name = file_path.stem
                    
                    dest_path = MODELS_ACTIVE / f"{model_name}.pt"
                    if not dest_path.exists():  # Don't overwrite existing
                        shutil.copy2(file_path, dest_path)
                        migrated_files += 1
                        print(f"âœ… Migrated model: {model_name}")
        
        # Create migration report
        migration_report = {
            'migration_date': datetime.now().isoformat(),
            'old_structure': str(old_workflow_data),
            'new_structure': str(DATA_ROOT),
            'files_migrated': migrated_files,
            'migration_workflow': migration['workflow_id']
        }
        
        report_path = migration_dir / 'outputs' / 'migration_report.json'
        with open(report_path, 'w') as f:
            json.dump(migration_report, f, indent=2)
        
        print(f"\nâœ… Migration completed!")
        print(f"ğŸ“Š Files migrated: {migrated_files}")
        print(f"ğŸ“‹ Migration report: {report_path}")
        print(f"\nğŸ’¡ You can now safely archive or remove the old 'workflow_data' directory")
        
    except Exception as e:
        logger.error(f"Migration failed: {str(e)}")
        print(f"âŒ Migration failed: {str(e)}")

def show_current_status():
    """Show current directory status"""
    print("\nğŸ“Š CURRENT DIRECTORY STATUS")
    print("=" * 60)
    
    manager = WorkflowManager()
    summary = manager.get_workflow_summary()
    
    if 'error' in summary:
        print(f"âŒ Error getting status: {summary['error']}")
        return
    
    print(f"ğŸƒ Active workflows: {summary['active_workflows']}")
    print(f"ğŸ“¦ Archived workflows: {summary['archived_workflows']}")
    print(f"ğŸ¤– Total models: {summary['total_models']}")
    print(f"ğŸ—‚ï¸ Temp directory size: {summary['temp_size_mb']} MB")
    
    if summary['workflows']:
        print("\nğŸ“‹ Recent workflows:")
        for workflow in summary['workflows']:
            print(f"  â€¢ {workflow['id']} ({workflow['type']}) - {workflow.get('created', 'Unknown date')}")

def main():
    """Main demonstration function"""
    parser = argparse.ArgumentParser(description="Directory Structure Demo & Migration Tool")
    parser.add_argument('--action', choices=['demo', 'migrate', 'status', 'all'], 
                       default='all', help='Action to perform')
    
    args = parser.parse_args()
    
    print("ğŸš€ PROJECT SIGHTLINE - DIRECTORY STRUCTURE TOOL")
    print("=" * 60)
    
    if args.action in ['demo', 'all']:
        demonstrate_new_structure()
        demonstrate_workflow_creation()
        demonstrate_file_organization()
    
    if args.action in ['migrate', 'all']:
        migrate_old_structure()
    
    if args.action in ['status', 'all']:
        show_current_status()
    
    print("\nâœ¨ Directory structure demonstration complete!")
    print("\nğŸ’¡ Next steps:")
    print("  â€¢ Update your workflow scripts to use the new WorkflowManager")
    print("  â€¢ Run migration if you have old data to preserve")  
    print("  â€¢ Enjoy the organized, intuitive file structure! ğŸ‰")

if __name__ == "__main__":
    main() 